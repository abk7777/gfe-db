{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef699b6",
   "metadata": {},
   "source": [
    "# Refactor notebook: gfedb_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca78758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Uncomment for Jupyter Notebook\n",
    "for path in ['../','../src/']:\n",
    "    sys.path.append(path) if path not in sys.path else \"\"\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import urllib.request\n",
    "from Bio import AlignIO\n",
    "from Bio.SeqFeature import SeqFeature\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from seqann.models.annotation import Annotation\n",
    "from Bio import SeqIO\n",
    "from pyard import ARD\n",
    "from seqann.gfe import GFE\n",
    "from csv import DictWriter\n",
    "from pathlib import Path\n",
    "from constants import *\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658f2d3",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4ba2f",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e8784d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbversion = \"3420\"\n",
    "verbose = True\n",
    "verbosity = 1\n",
    "alignments = True\n",
    "kir = False\n",
    "imgt_release = f'{dbversion[0]}.{dbversion[1:3]}.{dbversion[3]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdf2cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ard = ARD(dbversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c589e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfe_maker = GFE(verbose=verbose, \n",
    "    verbosity=verbosity,\n",
    "    load_features=False, \n",
    "    store_features=True,\n",
    "    loci=hla_loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b9de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output memory profile to check for leaks\n",
    "_mem_profile = True if '-p' in sys.argv else False\n",
    "\n",
    "if _mem_profile:\n",
    "    from pympler import tracker, muppy, summary\n",
    "    tr = tracker.SummaryTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a9114",
   "metadata": {},
   "source": [
    "### Refactored Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e77d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_hasher(seq, n=32):\n",
    "    \"\"\"Takes a nucleotide or amino acid sequence and returns a reproducible\n",
    "    integer UUID. Used to create shorter unique IDs since Neo4j cannot index \n",
    "    a full sequence. Can be also be used for any string.\"\"\"\n",
    "\n",
    "    m = hashlib.md5()\n",
    "    m.update(seq)\n",
    "\n",
    "    return str(int(m.hexdigest(), 16))[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "44ee0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hla_alignments(dbversion):\n",
    "    gen_aln = {l: {} for l in hla_loci}\n",
    "    nuc_aln = {l: {} for l in hla_loci}\n",
    "    prot_aln = {l: {} for l in hla_loci}\n",
    "\n",
    "    #logging.info(f'HLA alignments:\\n{hla_align}')\n",
    "\n",
    "    for loc in hla_align:\n",
    "        msf_gen = ''.join([data_dir, dbversion, \"/\", loc.split(\"-\")[1], \"_gen.msf\"])\n",
    "        msf_nuc = ''.join([data_dir, dbversion, \"/\", loc.split(\"-\")[1], \"_nuc.msf\"])\n",
    "        msf_prot = ''.join([data_dir, dbversion, \"/\", loc.split(\"-\")[1], \"_prot.msf\"])\n",
    "\n",
    "        logging.info(f'Loading {\"/\".join(msf_gen.split(\"/\")[-3:])}')\n",
    "        align_gen = AlignIO.read(open(msf_gen), \"msf\")\n",
    "        gen_seq = {\"HLA-\" + a.name: str(a.seq) for a in align_gen}\n",
    "        del align_gen\n",
    "        logging.info(f'{str(len(gen_seq))} genomic alignments loaded')\n",
    "        gen_aln.update({loc: gen_seq})\n",
    "\n",
    "        logging.info(f'Loading {\"/\".join(msf_nuc.split(\"/\")[-3:])}')\n",
    "        align_nuc = AlignIO.read(open(msf_nuc), \"msf\")\n",
    "        nuc_seq = {\"HLA-\" + a.name: str(a.seq) for a in align_nuc}\n",
    "        del align_nuc\n",
    "        logging.info(f'{str(len(nuc_seq))} nucleotide alignments loaded')\n",
    "        nuc_aln.update({loc: nuc_seq})\n",
    "\n",
    "        # https://github.com/ANHIG/IMGTHLA/issues/158\n",
    "        # if str(dbversion) == [\"3320\", \"3360\"]:\n",
    "        #    continue\n",
    "\n",
    "        logging.info(f'Loading {\"/\".join(msf_prot.split(\"/\")[-3:])}')\n",
    "        align_prot = AlignIO.read(open(msf_prot), \"msf\")\n",
    "        prot_seq = {\"HLA-\" + a.name: str(a.seq) for a in align_prot}\n",
    "        del align_prot\n",
    "        logging.info(f'{str(len(prot_seq))} protein alignments loaded')\n",
    "        prot_aln.update({loc: prot_seq})\n",
    "\n",
    "    return gen_aln, nuc_aln, prot_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18651296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(seqrecord):\n",
    "    j = 3 if len(seqrecord.features) > 3 else len(seqrecord.features)\n",
    "    fiveutr = [[\"five_prime_UTR\", SeqRecord(seq=seqrecord.features[i].extract(seqrecord.seq), id=\"1\")] for i in\n",
    "               range(0, j) if seqrecord.features[i].type != \"source\"\n",
    "               and seqrecord.features[i].type != \"CDS\" and isinstance(seqrecord.features[i], SeqFeature)\n",
    "               and not seqrecord.features[i].qualifiers]\n",
    "    feats = [[''.join([str(feat.type), \"_\", str(feat.qualifiers['number'][0])]), SeqRecord(seq=feat.extract(seqrecord.seq), id=\"1\")]\n",
    "             for feat in seqrecord.features if feat.type != \"source\"\n",
    "             and feat.type != \"CDS\" and isinstance(feat, SeqFeature)\n",
    "             and 'number' in feat.qualifiers]\n",
    "\n",
    "    threeutr = []\n",
    "    if len(seqrecord.features) > 1:\n",
    "        threeutr = [[\"three_prime_UTR\", SeqRecord(seq=seqrecord.features[i].extract(seqrecord.seq), id=\"1\")] for i in\n",
    "                    range(len(seqrecord.features) - 1, len(seqrecord.features)) if\n",
    "                    seqrecord.features[i].type != \"source\"\n",
    "                    and seqrecord.features[i].type != \"CDS\" and isinstance(seqrecord.features[i], SeqFeature)\n",
    "                    and not seqrecord.features[i].qualifiers]\n",
    "\n",
    "    feat_list = fiveutr + feats + threeutr\n",
    "    annotation = {k[0]: k[1] for k in feat_list}\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "565e9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns base pair and amino acid sequences from CDS data\n",
    "def get_cds(allele):\n",
    "\n",
    "    feat_types = [f.type for f in allele.features]\n",
    "    bp_seq = None\n",
    "    aa_seq = None\n",
    "    \n",
    "    if \"CDS\" in feat_types:\n",
    "        cds_features = allele.features[feat_types.index(\"CDS\")]\n",
    "        if 'translation' in cds_features.qualifiers:\n",
    "\n",
    "            if cds_features.location is None:\n",
    "                logging.info(f\"No CDS location for feature in allele: {allele.name}\")\n",
    "            else:\n",
    "                bp_seq = str(cds_features.extract(allele.seq))\n",
    "                aa_seq = cds_features.qualifiers['translation'][0]\n",
    "                \n",
    "    return bp_seq, aa_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b172eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streams dictionaries as rows to a file\n",
    "def append_dict_as_row(dict_row, file_path):\n",
    "\n",
    "    try:\n",
    "        header = list(dict_row.keys())\n",
    "\n",
    "        # Check if file exists\n",
    "        csv_file = Path(file_path)\n",
    "        if not csv_file.is_file():\n",
    "\n",
    "            # Create the file and add the header\n",
    "            with open(file_path, 'a+', newline='') as write_obj:\n",
    "                dict_writer = DictWriter(write_obj, fieldnames=header)\n",
    "                dict_writer.writeheader()\n",
    "\n",
    "        # Do not add an else statement or the first line will be skipped\n",
    "        with open(file_path, 'a+', newline='') as write_obj:\n",
    "            dict_writer = DictWriter(write_obj, fieldnames=header)\n",
    "            dict_writer.writerow(dict_row)\n",
    "\n",
    "        return\n",
    "    except Exception as err:\n",
    "        logging.error(f'Could not add row')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edee75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs memory of objects during execution to sheck for memory leaks\n",
    "if _mem_profile:\n",
    "    def memory_profiler(mode='all'):\n",
    "\n",
    "        # Print a summary of memory usage every n alleles\n",
    "        all_objects = muppy.get_objects()\n",
    "        sum2 = summary.summarize(all_objects)\n",
    "\n",
    "        original_stdout = sys.stdout\n",
    "\n",
    "        if mode == 'all' or mode == 'agg':\n",
    "            with open(\"summary_agg.txt\", \"a+\") as f:\n",
    "                sys.stdout = f\n",
    "                summary.print_(sum2)\n",
    "                sys.stdout = original_stdout;\n",
    "\n",
    "        if mode == 'all' or mode == 'diff':\n",
    "            with open(\"summary_diff.txt\", \"a+\") as f:\n",
    "                sys.stdout = f\n",
    "                tr.print_diff()\n",
    "                sys.stdout = original_stdout;    \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ee7ff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dat(data_dir, dbversion):\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Parsing DAT file...\")\n",
    "        dat_file = ''.join([data_dir, 'hla.', dbversion, \".dat\"])\n",
    "        \n",
    "        return SeqIO.parse(dat_file, \"imgt\")\n",
    "    \n",
    "    except Exception as err:\n",
    "        logging.error(f'Could not parse file: {dat_file}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef45aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(allele):\n",
    "    a_name = allele.description.split(\",\")[0].split(\"-\")[1]\n",
    "    groups = [[\"HLA-\" + ard.redux(a_name, grp), grp] if ard.redux(a_name, grp) != a_name else None for\n",
    "                grp in ard_groups]\n",
    "\n",
    "    # expre_chars = ['N', 'Q', 'L', 'S']\n",
    "    # to_second = lambda a: \":\".join(a.split(\":\")[0:2]) + \\\n",
    "    #    list(a)[-1] if list(a)[-1] in expre_chars and \\\n",
    "    #    len(a.split(\":\")) > 2 else \":\".join(a.split(\":\")[0:2])\n",
    "    # seco = [[to_second(a_name), \"2nd_FIELD\"]]\n",
    "\n",
    "    return groups #list(filter(None, groups)) # + seco # --> why filter(None, ...) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92d7fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactor builed gfes\n",
    "def build_GFE(allele):\n",
    "    \n",
    "    # Build and stream the GFE rows\n",
    "    try:\n",
    "        _seq = str(allele.seq)\n",
    "\n",
    "        gfe_row = {\n",
    "            \"gfe_name\": gfe,\n",
    "            \"allele_id\": allele.id,\n",
    "            \"locus\": locus,\n",
    "            \"hla_name\": hla_name,\n",
    "            \"a_name\": hla_name.split(\"-\")[1],\n",
    "            \"seq_id\": seq_hasher(_seq.encode('utf-8')),\n",
    "            \"sequence\": _seq,\n",
    "            \"length\": len(_seq),\n",
    "            \"imgt_release\": imgt_release\n",
    "        }\n",
    "\n",
    "        return gfe_row\n",
    "               \n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write GFE data for allele ID {allele.id}')\n",
    "        raise err "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "359342da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(feature, allele):\n",
    "    \n",
    "    try:\n",
    "        # features preprocessing steps\n",
    "        # 1) Convert seqann type to python dict using literal_eval\n",
    "        # 2) add GFE foreign keys: allele_id, hla_name\n",
    "        # 3) calculate columns: length             \n",
    "\n",
    "        # Append allele id's\n",
    "        # Note: Some alleles may have the same feature, but it may not be the same rank, \n",
    "        # so a feature should be identified with its allele by allele_id or HLA name\n",
    "\n",
    "        feature[\"gfe_name\"] = gfe\n",
    "        feature[\"term\"] = feature[\"term\"].upper()\n",
    "        feature[\"allele_id\"] = allele.id \n",
    "        feature[\"hla_name\"] = hla_name\n",
    "        feature[\"imgt_release\"] = imgt_release\n",
    "\n",
    "        # Avoid null values in CSV for Neo4j import\n",
    "        feature[\"hash_code\"] = \"none\" if not feature[\"hash_code\"] else feature[\"hash_code\"]\n",
    "\n",
    "        return feature\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write feature for allele {allele.id}')\n",
    "        logging.error(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6163be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_genomic_alignment(allele):\n",
    "\n",
    "    if allele.description.split(\",\")[0] in gen_aln[locus]:\n",
    "      \n",
    "        try:\n",
    "            \n",
    "            aligned_gen = gen_aln[locus][allele.description.split(\",\")[0]]\n",
    "\n",
    "            gen_align_row = {\n",
    "                \"label\": \"GEN_ALIGN\",\n",
    "                \"seq_id\": seq_hasher(aligned_gen.encode('utf-8')),\n",
    "                \"gfe_name\": gfe,\n",
    "                \"hla_name\": hla_name,\n",
    "                \"a_name\": hla_name.split(\"-\")[1],\n",
    "                \"length\": len(aligned_gen),\n",
    "                \"rank\": \"0\", # TO DO: confirm how this value is derived\n",
    "                \"bp_sequence\": aligned_gen,\n",
    "                \"aa_sequence\": \"\",\n",
    "                \"imgt_release\": imgt_release # 3.24.0 instead of 3240\n",
    "            }\n",
    "\n",
    "            return gen_align_row\n",
    "    \n",
    "        except Exceptions as err:\n",
    "            logging.error(f'Failed to write protein alignment for allele {allele.id}')\n",
    "            raise err\n",
    "    \n",
    "    else:\n",
    "        logging.info(f'No genomic alignments found')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b8df919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nucleotide_alignment(allele):\n",
    "    \n",
    "    if allele.description.split(\",\")[0] in nuc_aln[locus]:\n",
    "\n",
    "        try:\n",
    "            aligned_nuc = nuc_aln[locus][allele.description.split(\",\")[0]]\n",
    "\n",
    "            nuc_align_row = {\n",
    "                \"label\": \"NUC_ALIGN\",\n",
    "                \"seq_id\": seq_hasher(aligned_nuc.encode('utf-8')),\n",
    "                \"gfe_name\": gfe,\n",
    "                \"hla_name\": hla_name,\n",
    "                \"a_name\": hla_name.split(\"-\")[1],\n",
    "                \"length\": len(aligned_nuc),\n",
    "                \"rank\": \"0\", # TO DO: confirm how this value is derived\n",
    "                \"bp_sequence\": aligned_nuc,\n",
    "                \"aa_sequence\": \"\",\n",
    "                \"imgt_release\": imgt_release\n",
    "            }\n",
    "\n",
    "            return nuc_align_row\n",
    "        \n",
    "        except Exceptions as err:\n",
    "            logging.error(f'Failed to write protein alignment for allele {allele.id}')\n",
    "            raise err\n",
    "    \n",
    "    else:\n",
    "        logging.info(f'No nucleotide alignments found')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63b9b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_protein_alignment(allele):\n",
    "    \n",
    "    if allele.description.split(\",\")[0] in prot_aln[locus]:\n",
    "        \n",
    "        try:\n",
    "            aligned_prot = prot_aln[locus][allele.description.split(\",\")[0]]\n",
    "\n",
    "            prot_align_row = {\n",
    "                \"label\": \"PROT_ALIGN\",\n",
    "                \"seq_id\": seq_hasher(aligned_prot.encode('utf-8')),\n",
    "                \"gfe_name\": gfe,\n",
    "                \"hla_name\": hla_name,\n",
    "                \"a_name\": hla_name.split(\"-\")[1],\n",
    "                \"length\": len(aligned_prot),\n",
    "                \"rank\": \"0\", # TO DO: confirm how this value is derived\n",
    "                \"bp_sequence\": \"\",\n",
    "                \"aa_sequence\": aligned_prot,\n",
    "                \"imgt_release\": imgt_release\n",
    "            }\n",
    "\n",
    "            return prot_align_row\n",
    "        \n",
    "        except Exceptions as err:\n",
    "            logging.error(f'Failed to write protein alignment for allele {allele.id}')\n",
    "            raise err\n",
    "    \n",
    "    else:\n",
    "        logging.info(f'No protein alignments found')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8165031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_group(group, allele):\n",
    "    # Build and stream the ARD group rows\n",
    "    try:\n",
    "        group_row = {\n",
    "            \"gfe_name\": gfe,\n",
    "            \"allele_id\": allele.id,\n",
    "            \"hla_name\": hla_name,\n",
    "            \"a_name\": hla_name.split(\"-\")[1],\n",
    "            \"ard_id\": group[0],\n",
    "            \"ard_name\": group[1],\n",
    "            \"locus\": locus,\n",
    "            \"imgt_release\": imgt_release\n",
    "        }\n",
    "\n",
    "        file_path = f'{data_dir}csv/all_groups.{dbversion}.csv'\n",
    "        \n",
    "        return group_row\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write groups for allele {allele.id}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1565f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cds(allele):\n",
    "    # Build and stream the CDS rows\n",
    "    try:\n",
    "        # Build CDS dict for CSV export, foreign key: allele_id, hla_name\n",
    "        bp_seq, aa_seq = get_cds(allele)\n",
    "\n",
    "        cds_row = {\n",
    "            \"gfe_name\": gfe,\n",
    "            # \"gfe_sequence\": str(allele.seq),\n",
    "            # \"allele_id\": allele.id,\n",
    "            # \"hla_name\": hla_name,\n",
    "            \"bp_seq_id\": seq_hasher(bp_seq.encode('utf-8')),\n",
    "            \"bp_sequence\": bp_seq,\n",
    "            \"aa_seq_id\": seq_hasher(aa_seq.encode('utf-8')),\n",
    "            \"aa_sequence\": aa_seq,\n",
    "            # \"imgt_release\": imgt_release\n",
    "        }\n",
    "\n",
    "        return cds_row\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write CDS data for allele {allele.id}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49a63489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_allele(allele):\n",
    "    \n",
    "    hla_name = allele.description.split(\",\")[0]\n",
    "\n",
    "    complete_annotation = get_features(allele)\n",
    "\n",
    "    ann = Annotation(annotation=complete_annotation,\n",
    "            method='match',\n",
    "            complete_annotation=True)\n",
    "\n",
    "    # This process takes a long time\n",
    "    logging.info(f\"Getting GFE data for allele {allele.id}...\")\n",
    "    features, gfe = gfe_maker.get_gfe(ann, locus)\n",
    "\n",
    "    # gfe_sequences\n",
    "    file_name = ''.join([data_dir, f'csv/gfe_sequences.{dbversion}.csv'])\n",
    "    gfe_row = build_GFE(allele)\n",
    "    append_dict_as_row(gfe_row, file_name)\n",
    "\n",
    "    # all_features\n",
    "    # features contains list of seqann objects, converts to dict, destructive step\n",
    "    features = \\\n",
    "        [ast.literal_eval(str(feature) \\\n",
    "            .replace('\\'', '\"') \\\n",
    "            .replace('\\n', '')) \\\n",
    "            for feature in features]  \n",
    "\n",
    "    file_path = f'{data_dir}csv/all_features.{dbversion}.csv'\n",
    "\n",
    "    for feature in features:\n",
    "        feature_row = build_feature(feature, allele)\n",
    "        append_dict_as_row(feature_row, file_path)\n",
    "\n",
    "    # all_alignments\n",
    "    if alignments:\n",
    "        file_path = f'{data_dir}csv/all_alignments.{dbversion}.csv'\n",
    "        append_dict_as_row(build_genomic_alignment(allele), file_path)\n",
    "        append_dict_as_row(build_nucleotide_alignment(allele), file_path)\n",
    "        append_dict_as_row(build_protein_alignment(allele), file_path)\n",
    "\n",
    "    # all_groups\n",
    "    groups = get_groups(allele)\n",
    "\n",
    "    file_path = f'{data_dir}csv/all_groups.{dbversion}.csv'\n",
    "\n",
    "    for group in groups:\n",
    "        group_row = build_group(group, allele)\n",
    "        append_dict_as_row(group_row, file_path)\n",
    "\n",
    "    # all_cds\n",
    "    file_path = f'{data_dir}csv/all_cds.{dbversion}.csv'\n",
    "    append_dict_as_row(build_cds(allele), file_path)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dbba65",
   "metadata": {},
   "source": [
    "### Allele Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e448ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logging.debug(f'args: {sys.argv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d28b5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 02:39:18 - root - INFO - Parsing DAT file...\n"
     ]
    }
   ],
   "source": [
    "alleles = parse_dat(data_dir, \"3420\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ed6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 02:35:17 - root - INFO - Loading data/3420/A_gen.msf\n",
      "2021-04-25 02:35:18 - root - INFO - 3067 genomic alignments loaded\n",
      "2021-04-25 02:35:18 - root - INFO - Loading data/3420/A_nuc.msf\n",
      "2021-04-25 02:35:18 - root - INFO - 6291 nucleotide alignments loaded\n",
      "2021-04-25 02:35:18 - root - INFO - Loading data/3420/A_prot.msf\n",
      "2021-04-25 02:35:19 - root - INFO - 6291 protein alignments loaded\n",
      "2021-04-25 02:35:19 - root - INFO - Loading data/3420/B_gen.msf\n",
      "2021-04-25 02:35:19 - root - INFO - 3643 genomic alignments loaded\n",
      "2021-04-25 02:35:19 - root - INFO - Loading data/3420/B_nuc.msf\n",
      "2021-04-25 02:35:20 - root - INFO - 7561 nucleotide alignments loaded\n",
      "2021-04-25 02:35:20 - root - INFO - Loading data/3420/B_prot.msf\n",
      "2021-04-25 02:35:21 - root - INFO - 7561 protein alignments loaded\n",
      "2021-04-25 02:35:21 - root - INFO - Loading data/3420/C_gen.msf\n",
      "2021-04-25 02:35:21 - root - INFO - 3508 genomic alignments loaded\n",
      "2021-04-25 02:35:21 - root - INFO - Loading data/3420/C_nuc.msf\n",
      "2021-04-25 02:35:22 - root - INFO - 6223 nucleotide alignments loaded\n",
      "2021-04-25 02:35:22 - root - INFO - Loading data/3420/C_prot.msf\n",
      "2021-04-25 02:35:22 - root - INFO - 6223 protein alignments loaded\n",
      "2021-04-25 02:35:22 - root - INFO - Loading data/3420/DRB1_gen.msf\n",
      "2021-04-25 02:35:22 - root - INFO - 178 genomic alignments loaded\n",
      "2021-04-25 02:35:22 - root - INFO - Loading data/3420/DRB1_nuc.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 2837 nucleotide alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DRB1_prot.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 2837 protein alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQB1_gen.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 381 genomic alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQB1_nuc.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 1930 nucleotide alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQB1_prot.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 1930 protein alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPB1_gen.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 513 genomic alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPB1_nuc.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 1654 nucleotide alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPB1_prot.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 1654 protein alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQA1_gen.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 163 genomic alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQA1_nuc.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 264 nucleotide alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DQA1_prot.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 264 protein alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPA1_gen.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 120 genomic alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPA1_nuc.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 216 nucleotide alignments loaded\n",
      "2021-04-25 02:35:23 - root - INFO - Loading data/3420/DPA1_prot.msf\n",
      "2021-04-25 02:35:23 - root - INFO - 216 protein alignments loaded\n"
     ]
    }
   ],
   "source": [
    "# Load alignments data\n",
    "if alignments:\n",
    "    gen_aln, nuc_aln, prot_aln = hla_alignments(dbversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5187411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 02:40:16 - root - INFO - Getting GFE data for allele HLA15760.1...\n",
      "2021-04-25 02:40:17 - Logger.seqann.gfe - INFO - GFE = HLA-Aw46-1-1-1-1-1-90-1-1-1-1-1-1-1-1-1-18\n"
     ]
    }
   ],
   "source": [
    "for allele in alleles:\n",
    "    \n",
    "    locus = allele.description.split(\",\")[0].split(\"*\")[0]\n",
    "    \n",
    "    allele_can_be_processed = \\\n",
    "        hasattr(allele, 'seq') and \\\n",
    "        (locus in hla_loci or locus == \"DRB5\") and \\\n",
    "        (len(str(allele.seq)) > 5)\n",
    "    \n",
    "    if allele_can_be_processed:\n",
    "        process_allele(allele)\n",
    "    else:\n",
    "        logger.warn(f'Did not process allele: {hla_name} for locus {locus}')\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO - Conver these to generators\n",
    "gen_aln, nuc_aln, prot_aln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f33965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2efc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfe-db",
   "language": "python",
   "name": "gfe-db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
