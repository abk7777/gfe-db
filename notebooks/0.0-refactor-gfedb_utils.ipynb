{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef699b6",
   "metadata": {},
   "source": [
    "# Refactor notebook: gfedb_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca78758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Uncomment for Jupyter Notebook\n",
    "for path in ['../','../src/']:\n",
    "    sys.path.append(path) if path not in sys.path else \"\"\n",
    "\n",
    "import logging\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import urllib.request\n",
    "from Bio import AlignIO\n",
    "from Bio.SeqFeature import SeqFeature\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from seqann.models.annotation import Annotation\n",
    "from Bio import SeqIO\n",
    "from pyard import ARD\n",
    "from seqann.gfe import GFE\n",
    "from csv import DictWriter\n",
    "from pathlib import Path\n",
    "from constants import *\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcae392",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logging.debug(f'args: {sys.argv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a4e01",
   "metadata": {},
   "source": [
    "## Refactored Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77d17d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_hasher(seq, n=32):\n",
    "    \"\"\"Takes a nucleotide or amino acid sequence and returns a reproducible\n",
    "    integer UUID. Used to create shorter unique IDs since Neo4j cannot index \n",
    "    a full sequence. Can be also be used for any string.\"\"\"\n",
    "\n",
    "    m = hashlib.md5()\n",
    "    m.update(seq)\n",
    "\n",
    "    return str(int(m.hexdigest(), 16))[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af787af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hla_alignments(dbversion, align_type=\"gen\"):\n",
    "    \n",
    "    if align_type in [\"gen\", \"genomic\"]:\n",
    "        align_type = \"gen\"\n",
    "    elif align_type in [\"nuc\", \"nucleotide\"]:\n",
    "        align_type = \"nuc\"\n",
    "    elif align_type in [\"prot\", \"protein\"]:\n",
    "        align_type = \"prot\"\n",
    "    else:\n",
    "        raise ValueError(f'Could not recognize align_type = \"{align_type}\"')\n",
    "        \n",
    "    alignment = {l: {} for l in hla_loci}\n",
    "    \n",
    "    for locus in hla_align:\n",
    "\n",
    "        msf = ''.join([data_dir, dbversion, \"/\", locus.split(\"-\")[1], f\"_{align_type}.msf\"])\n",
    "\n",
    "        logging.info(f'Loading {\"/\".join(msf.split(\"/\")[-3:])}')\n",
    "        align_data = AlignIO.read(open(msf), \"msf\")\n",
    "\n",
    "        seq = {\"HLA-\" + a.name: str(a.seq) for a in align_data}\n",
    "\n",
    "        del align_data\n",
    "\n",
    "        logging.info(f'{str(len(seq))} protein alignments loaded')\n",
    "        alignment.update({locus: seq})\n",
    "\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18651296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(seqrecord):\n",
    "    j = 3 if len(seqrecord.features) > 3 else len(seqrecord.features)\n",
    "    fiveutr = [[\"five_prime_UTR\", SeqRecord(seq=seqrecord.features[i].extract(seqrecord.seq), id=\"1\")] for i in\n",
    "               range(0, j) if seqrecord.features[i].type != \"source\"\n",
    "               and seqrecord.features[i].type != \"CDS\" and isinstance(seqrecord.features[i], SeqFeature)\n",
    "               and not seqrecord.features[i].qualifiers]\n",
    "    feats = [[''.join([str(feat.type), \"_\", str(feat.qualifiers['number'][0])]), SeqRecord(seq=feat.extract(seqrecord.seq), id=\"1\")]\n",
    "             for feat in seqrecord.features if feat.type != \"source\"\n",
    "             and feat.type != \"CDS\" and isinstance(feat, SeqFeature)\n",
    "             and 'number' in feat.qualifiers]\n",
    "\n",
    "    threeutr = []\n",
    "    if len(seqrecord.features) > 1:\n",
    "        threeutr = [[\"three_prime_UTR\", SeqRecord(seq=seqrecord.features[i].extract(seqrecord.seq), id=\"1\")] for i in\n",
    "                    range(len(seqrecord.features) - 1, len(seqrecord.features)) if\n",
    "                    seqrecord.features[i].type != \"source\"\n",
    "                    and seqrecord.features[i].type != \"CDS\" and isinstance(seqrecord.features[i], SeqFeature)\n",
    "                    and not seqrecord.features[i].qualifiers]\n",
    "\n",
    "    feat_list = fiveutr + feats + threeutr\n",
    "    annotation = {k[0]: k[1] for k in feat_list}\n",
    "\n",
    "    return annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565e9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns base pair and amino acid sequences from CDS data\n",
    "def get_cds(allele):\n",
    "\n",
    "    feat_types = [f.type for f in allele.features]\n",
    "    bp_seq = None\n",
    "    aa_seq = None\n",
    "    \n",
    "    if \"CDS\" in feat_types:\n",
    "        cds_features = allele.features[feat_types.index(\"CDS\")]\n",
    "        if 'translation' in cds_features.qualifiers:\n",
    "\n",
    "            if cds_features.location is None:\n",
    "                logging.info(f\"No CDS location for feature in allele: {allele.name}\")\n",
    "            else:\n",
    "                bp_seq = str(cds_features.extract(allele.seq))\n",
    "                aa_seq = cds_features.qualifiers['translation'][0]\n",
    "                \n",
    "    return bp_seq, aa_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b172eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streams dictionaries as rows to a file\n",
    "def append_dict_as_row(dict_row, file_path):\n",
    "\n",
    "    try:\n",
    "        header = list(dict_row.keys())\n",
    "\n",
    "        # Check if file exists\n",
    "        csv_file = Path(file_path)\n",
    "        if not csv_file.is_file():\n",
    "\n",
    "            # Create the file and add the header\n",
    "            with open(file_path, 'a+', newline='') as write_obj:\n",
    "                dict_writer = DictWriter(write_obj, fieldnames=header)\n",
    "                dict_writer.writeheader()\n",
    "\n",
    "        # Do not add an else statement or the first line will be skipped\n",
    "        with open(file_path, 'a+', newline='') as write_obj:\n",
    "            dict_writer = DictWriter(write_obj, fieldnames=header)\n",
    "            dict_writer.writerow(dict_row)\n",
    "\n",
    "        return\n",
    "    except Exception as err:\n",
    "        logging.error(f'Could not add row')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edee75a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs memory of objects during execution to sheck for memory leaks\n",
    "_mem_profile = True\n",
    "if _mem_profile:\n",
    "    def memory_profiler(mode='all'):\n",
    "\n",
    "        # Print a summary of memory usage every n alleles\n",
    "        all_objects = muppy.get_objects()\n",
    "        sum2 = summary.summarize(all_objects)\n",
    "\n",
    "        original_stdout = sys.stdout\n",
    "\n",
    "        if mode == 'all' or mode == 'agg':\n",
    "            with open(\"summary_agg.txt\", \"a+\") as f:\n",
    "                sys.stdout = f\n",
    "                summary.print_(sum2)\n",
    "                sys.stdout = original_stdout;\n",
    "\n",
    "        if mode == 'all' or mode == 'diff':\n",
    "            with open(\"summary_diff.txt\", \"a+\") as f:\n",
    "                sys.stdout = f\n",
    "                tr.print_diff()\n",
    "                sys.stdout = original_stdout;    \n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7ff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dat(data_dir, dbversion):\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Parsing DAT file...\")\n",
    "        dat_file = ''.join([data_dir, 'hla.', dbversion, \".dat\"])\n",
    "        \n",
    "        return SeqIO.parse(dat_file, \"imgt\")\n",
    "    \n",
    "    except Exception as err:\n",
    "        logging.error(f'Could not parse file: {dat_file}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef45aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(allele):\n",
    "    a_name = allele.description.split(\",\")[0].split(\"-\")[1]\n",
    "    groups = [[\"HLA-\" + ard.redux(a_name, grp), grp] if ard.redux(a_name, grp) != a_name else None for\n",
    "                grp in ard_groups]\n",
    "\n",
    "    # expre_chars = ['N', 'Q', 'L', 'S']\n",
    "    # to_second = lambda a: \":\".join(a.split(\":\")[0:2]) + \\\n",
    "    #    list(a)[-1] if list(a)[-1] in expre_chars and \\\n",
    "    #    len(a.split(\":\")) > 2 else \":\".join(a.split(\":\")[0:2])\n",
    "    # seco = [[to_second(a_name), \"2nd_FIELD\"]]\n",
    "\n",
    "    return groups #list(filter(None, groups)) # + seco # --> why filter(None, ...) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af218ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refactor builed gfes\n",
    "def build_GFE(allele):\n",
    "    \n",
    "    # Build and stream the GFE rows\n",
    "    try:\n",
    "        _seq = str(allele.seq)\n",
    "\n",
    "        row = {\n",
    "            \"gfe_name\": gfe_name,\n",
    "            \"allele_id\": allele.id,\n",
    "            \"locus\": locus,\n",
    "            \"hla_name\": hla_name,\n",
    "            #\"a_name\": hla_name.split(\"-\")[1],\n",
    "            \"seq_id\": seq_hasher(_seq.encode('utf-8')),\n",
    "            \"sequence\": _seq,\n",
    "            \"length\": len(_seq),\n",
    "            \"imgt_release\": imgt_release\n",
    "        }\n",
    "\n",
    "        return row\n",
    "               \n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write GFE data for allele ID {allele.id}')\n",
    "        raise err "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e17fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(feature):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        feature[\"gfe_name\"] = gfe_name\n",
    "        feature[\"term\"] = feature[\"term\"].upper()\n",
    "        feature[\"allele_id\"] = allele.id \n",
    "        feature[\"hla_name\"] = hla_name\n",
    "        feature[\"imgt_release\"] = imgt_release\n",
    "\n",
    "        # Avoid null values in CSV for Neo4j import\n",
    "        feature[\"hash_code\"] = \"none\" if not feature[\"hash_code\"] else feature[\"hash_code\"]\n",
    "\n",
    "        return feature\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write feature for allele {allele.id}')\n",
    "        logging.error(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b45dd23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_alignment(allele, alignments, align_type=\"genomic\"):\n",
    "\n",
    "    if align_type in [\"gen\", \"genomic\"]:\n",
    "        align_type = \"genomic\"\n",
    "        label = \"GEN_ALIGN\"\n",
    "    elif align_type in [\"nuc\", \"nucleotide\"]:\n",
    "        align_type = \"nucleotide\"\n",
    "        label = \"NUC_ALIGN\"\n",
    "    elif align_type in [\"prot\", \"protein\"]:\n",
    "        align_type = \"protein\"\n",
    "        label = \"PROT_ALIGN\"\n",
    "    else:\n",
    "        raise ValueError(f'Could not recognize align_type = \"{align_type}\"')\n",
    "\n",
    "    if allele.description.split(\",\")[0] in alignments[align_type][locus]:\n",
    "      \n",
    "        try:\n",
    "            \n",
    "            alignment = alignments[align_type][locus][allele.description.split(\",\")[0]]\n",
    "\n",
    "            row = {\n",
    "                \"label\": label,\n",
    "                \"seq_id\": seq_hasher(alignment.encode('utf-8')),\n",
    "                \"gfe_name\": gfe_name,\n",
    "                \"hla_name\": hla_name,\n",
    "                #\"a_name\": hla_name.split(\"-\")[1],\n",
    "                \"length\": len(alignment),\n",
    "                \"rank\": \"0\", # TO DO: confirm how this value is derived\n",
    "                #\"bp_sequence\": alignment if align_type in [\"genomic\", \"nucleotide\"] else \"\",\n",
    "                #\"aa_sequence\": \"\",\n",
    "                \"imgt_release\": imgt_release # 3.24.0 instead of 3240\n",
    "            }\n",
    "            \n",
    "            if align_type == \"protein\":\n",
    "                row.update({\n",
    "                \"bp_sequence\": \"\",\n",
    "                \"aa_sequence\": alignment,\n",
    "                })\n",
    "            else:\n",
    "                row.update({\n",
    "                \"bp_sequence\": alignment,\n",
    "                \"aa_sequence\": \"\",\n",
    "                })\n",
    "                \n",
    "            return row\n",
    "    \n",
    "        except Exception as err:\n",
    "            logging.error(f'Failed to write {align_type} alignment for allele {allele.id}')\n",
    "            raise err\n",
    "    \n",
    "    else:\n",
    "        logging.info(f'No {align_type} alignments found')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2502cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_group(group, allele):\n",
    "    # Build and stream the ARD group rows\n",
    "    try:\n",
    "        row = {\n",
    "            \"gfe_name\": gfe_name,\n",
    "            \"allele_id\": allele.id,\n",
    "            \"hla_name\": hla_name,\n",
    "            #\"a_name\": hla_name.split(\"-\")[1],\n",
    "            \"ard_id\": group[0],\n",
    "            \"ard_name\": group[1],\n",
    "            \"locus\": locus,\n",
    "            \"imgt_release\": imgt_release\n",
    "        }\n",
    "        \n",
    "        return row\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write groups for allele {allele.id}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd6ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cds(allele):\n",
    "    # Build and stream the CDS rows\n",
    "    try:\n",
    "        # Build CDS dict for CSV export, foreign key: allele_id, hla_name\n",
    "        bp_seq, aa_seq = get_cds(allele)\n",
    "\n",
    "        row = {\n",
    "            \"gfe_name\": gfe_name,\n",
    "            # \"gfe_sequence\": str(allele.seq),\n",
    "            # \"allele_id\": allele.id,\n",
    "            # \"hla_name\": hla_name,\n",
    "            \"bp_seq_id\": seq_hasher(bp_seq.encode('utf-8')),\n",
    "            \"bp_sequence\": bp_seq,\n",
    "            \"aa_seq_id\": seq_hasher(aa_seq.encode('utf-8')),\n",
    "            \"aa_sequence\": aa_seq,\n",
    "            # \"imgt_release\": imgt_release\n",
    "        }\n",
    "\n",
    "        return row\n",
    "\n",
    "    except Exception as err:\n",
    "        logging.error(f'Failed to write CDS data for allele {allele.id}')\n",
    "        raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6b7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfe_from_allele(allele):\n",
    "\n",
    "    complete_annotation = get_features(allele)\n",
    "\n",
    "    ann = Annotation(annotation=complete_annotation,\n",
    "            method='match',\n",
    "            complete_annotation=True)\n",
    "\n",
    "    # This process takes a long time\n",
    "    logging.info(f\"Getting GFE data for allele {allele.id}...\")\n",
    "    features, gfe = gfe_maker.get_gfe(ann, locus)\n",
    "        \n",
    "    return { \n",
    "        \"name\": gfe,\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7834cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_allele(allele, alignments, csv_path=None):\n",
    "    \n",
    "    csv_path = csv_path[:-1] if csv_path[-1] == \"/\" else path\n",
    "\n",
    "    # gfe_sequences\n",
    "    file_name = f'{csv_path}/gfe_sequences.{dbversion}.csv'\n",
    "    gfe_row = build_GFE(allele)\n",
    "    append_dict_as_row(gfe_row, file_name)\n",
    "\n",
    "    # all_features\n",
    "    \n",
    "    # features preprocessing steps\n",
    "    # 1) Convert seqann type to python dict using literal_eval\n",
    "    # 2) add GFE foreign keys: allele_id, hla_name\n",
    "    # 3) calculate columns: length             \n",
    "\n",
    "    # Append allele id's\n",
    "    # Note: Some alleles may have the same feature, but it may not be the same rank, \n",
    "    # so a feature should be identified with its allele by allele_id or HLA name\n",
    "    \n",
    "    # features contains list of seqann objects, converts to dict, destructive step\n",
    "    features = \\\n",
    "        [ast.literal_eval(str(feature) \\\n",
    "            .replace('\\'', '\"') \\\n",
    "            .replace('\\n', '')) \\\n",
    "            for feature in gfe_features]  \n",
    "\n",
    "    file_name = f'{csv_path}/all_features.{dbversion}.csv'\n",
    "\n",
    "    for feature in features:\n",
    "        feature_row = build_feature(feature)\n",
    "        append_dict_as_row(feature_row, file_name)\n",
    "\n",
    "    # all_alignments\n",
    "    if alignments:\n",
    "        file_name = f'{csv_path}/all_alignments.{dbversion}.csv'\n",
    "        \n",
    "        for align_type in [\"genomic\", \"nucleotide\", \"protein\"]:\n",
    "            append_dict_as_row(\n",
    "                build_alignment(allele=allele, \n",
    "                                alignments=alignments_dict,\n",
    "                                align_type=align_type), \n",
    "                file_name)\n",
    "            \n",
    "    # all_groups\n",
    "    groups = get_groups(allele)\n",
    "\n",
    "    file_name = f'{csv_path}/all_groups.{dbversion}.csv'\n",
    "\n",
    "    for group in groups:\n",
    "        group_row = build_group(group, allele)\n",
    "        append_dict_as_row(group_row, file_name)\n",
    "\n",
    "    # all_cds\n",
    "    file_name = f'{csv_path}/all_cds.{dbversion}.csv'\n",
    "    append_dict_as_row(build_cds(allele), file_name)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb4d27",
   "metadata": {},
   "source": [
    "## Allele Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919e3d2",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a638c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbversion = \"3420\"\n",
    "verbose = True\n",
    "verbosity = 1\n",
    "alignments = True\n",
    "kir = False\n",
    "imgt_release = f'{dbversion[0]}.{dbversion[1:3]}.{dbversion[3]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2536e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ard = ARD(dbversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f24d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfe_maker = GFE(verbose=verbose, \n",
    "    verbosity=verbosity,\n",
    "    load_features=False, \n",
    "    store_features=True,\n",
    "    loci=hla_loci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9de01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output memory profile to check for leaks\n",
    "_mem_profile = True if '-p' in sys.argv else False\n",
    "\n",
    "if _mem_profile:\n",
    "    from pympler import tracker, muppy, summary\n",
    "    tr = tracker.SummaryTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d28b5cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-24 14:40:17 - root - INFO - Parsing DAT file...\n"
     ]
    }
   ],
   "source": [
    "alleles = parse_dat(data_dir, \"3420\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bd827c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-24 14:40:48 - root - INFO - Loading data/3420/A_gen.msf\n",
      "2021-05-24 14:40:49 - root - INFO - 3067 protein alignments loaded\n",
      "2021-05-24 14:40:49 - root - INFO - Loading data/3420/B_gen.msf\n",
      "2021-05-24 14:40:50 - root - INFO - 3643 protein alignments loaded\n",
      "2021-05-24 14:40:50 - root - INFO - Loading data/3420/C_gen.msf\n",
      "2021-05-24 14:40:50 - root - INFO - 3508 protein alignments loaded\n",
      "2021-05-24 14:40:50 - root - INFO - Loading data/3420/DRB1_gen.msf\n",
      "2021-05-24 14:40:50 - root - INFO - 178 protein alignments loaded\n",
      "2021-05-24 14:40:50 - root - INFO - Loading data/3420/DQB1_gen.msf\n",
      "2021-05-24 14:40:50 - root - INFO - 381 protein alignments loaded\n",
      "2021-05-24 14:40:50 - root - INFO - Loading data/3420/DPB1_gen.msf\n",
      "2021-05-24 14:40:51 - root - INFO - 513 protein alignments loaded\n",
      "2021-05-24 14:40:51 - root - INFO - Loading data/3420/DQA1_gen.msf\n",
      "2021-05-24 14:40:51 - root - INFO - 163 protein alignments loaded\n",
      "2021-05-24 14:40:51 - root - INFO - Loading data/3420/DPA1_gen.msf\n",
      "2021-05-24 14:40:51 - root - INFO - 120 protein alignments loaded\n",
      "2021-05-24 14:40:51 - root - INFO - Loading data/3420/A_nuc.msf\n",
      "2021-05-24 14:40:51 - root - INFO - 6291 protein alignments loaded\n",
      "2021-05-24 14:40:51 - root - INFO - Loading data/3420/B_nuc.msf\n",
      "2021-05-24 14:40:52 - root - INFO - 7561 protein alignments loaded\n",
      "2021-05-24 14:40:52 - root - INFO - Loading data/3420/C_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 6223 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/DRB1_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 2837 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/DQB1_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 1930 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/DPB1_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 1654 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/DQA1_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 264 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/DPA1_nuc.msf\n",
      "2021-05-24 14:40:53 - root - INFO - 216 protein alignments loaded\n",
      "2021-05-24 14:40:53 - root - INFO - Loading data/3420/A_prot.msf\n",
      "2021-05-24 14:40:54 - root - INFO - 6291 protein alignments loaded\n",
      "2021-05-24 14:40:54 - root - INFO - Loading data/3420/B_prot.msf\n",
      "2021-05-24 14:40:54 - root - INFO - 7561 protein alignments loaded\n",
      "2021-05-24 14:40:54 - root - INFO - Loading data/3420/C_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 6223 protein alignments loaded\n",
      "2021-05-24 14:40:55 - root - INFO - Loading data/3420/DRB1_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 2837 protein alignments loaded\n",
      "2021-05-24 14:40:55 - root - INFO - Loading data/3420/DQB1_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 1930 protein alignments loaded\n",
      "2021-05-24 14:40:55 - root - INFO - Loading data/3420/DPB1_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 1654 protein alignments loaded\n",
      "2021-05-24 14:40:55 - root - INFO - Loading data/3420/DQA1_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 264 protein alignments loaded\n",
      "2021-05-24 14:40:55 - root - INFO - Loading data/3420/DPA1_prot.msf\n",
      "2021-05-24 14:40:55 - root - INFO - 216 protein alignments loaded\n"
     ]
    }
   ],
   "source": [
    "# Load alignments data\n",
    "if alignments:\n",
    "    alignments_dict = {\n",
    "        \"genomic\": parse_hla_alignments(dbversion, align_type=\"genomic\"),\n",
    "        \"nucleotide\": parse_hla_alignments(dbversion, align_type=\"nucleotide\"),\n",
    "        \"protein\": parse_hla_alignments(dbversion, align_type=\"protein\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89e05d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../data/csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad963d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5187411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-24 15:35:43 - root - INFO - Getting GFE data for allele HLA17985.1...\n",
      "2021-05-24 15:35:44 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-1-1-39-1-1-1-1-1-1-1-1-1-4\n",
      "2021-05-24 15:35:44 - root - INFO - Getting GFE data for allele HLA18246.1...\n",
      "2021-05-24 15:35:44 - Logger.seqann.gfe - INFO - GFE = HLA-Aw414-1-1-1-1-1-1-1-1-1-898-1-1-1-1-1-4\n",
      "2021-05-24 15:35:44 - root - INFO - Getting GFE data for allele HLA18976.1...\n",
      "2021-05-24 15:35:44 - Logger.seqann.gfe - INFO - GFE = HLA-Aw414-1-1-1-341-1-1-1-1-1-1-1-1-1-1-1-4\n",
      "2021-05-24 15:35:44 - root - INFO - Getting GFE data for allele HLA18991.1...\n",
      "2021-05-24 15:35:44 - Logger.seqann.gfe - INFO - GFE = HLA-Aw1206-1-1-1-878-1-1-1-1-1-1-1-1-1-1-1-322\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19155.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-1-1-1-1-322-1-1-1-1-1-1-1-19\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19049.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-1-1-250-1-1-1-1-1-1-1-1-1-19\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19098.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-43-1-1-1-1-1-1-1-1-1-1-1-4\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19296.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-883-1-1-1-1-1-1-1-1-1-1-1-4\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19336.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-884-1-1-1-1-1-1-1-1-1-1-1-4\n",
      "2021-05-24 15:35:45 - root - INFO - Getting GFE data for allele HLA19701.1...\n",
      "2021-05-24 15:35:45 - Logger.seqann.gfe - INFO - GFE = HLA-Aw2-1-1-1-1-1-1537-1-1-1-1-1-1-1-1-1-4\n"
     ]
    }
   ],
   "source": [
    "for idx, allele in enumerate(alleles):\n",
    "    \n",
    "    if idx == limit:\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        locus = allele.description.split(\",\")[0].split(\"*\")[0]\n",
    "        hla_name = allele.description.split(\",\")[0]\n",
    "\n",
    "        allele_can_be_processed = \\\n",
    "            hasattr(allele, 'seq') and \\\n",
    "            (locus in hla_loci or locus == \"DRB5\") and \\\n",
    "            (len(str(allele.seq)) > 5)\n",
    "\n",
    "        if allele_can_be_processed:\n",
    "            \n",
    "            gfe = gfe_from_allele(allele)\n",
    "            gfe_name = gfe[\"name\"]\n",
    "            gfe_features = gfe[\"features\"]\n",
    "            \n",
    "            # Process allele and output rows to CSV\n",
    "            process_allele(\n",
    "                allele=allele, \n",
    "                alignments=alignments_dict,\n",
    "                csv_path=csv_path)\n",
    "            \n",
    "        else:\n",
    "            logger.warn(f'Skipping allele {hla_name} for locus {locus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af2fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfe-db",
   "language": "python",
   "name": "gfe-db"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
